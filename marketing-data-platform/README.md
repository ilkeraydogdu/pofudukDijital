# Marketing Data Platform ğŸš€

KVKK/GDPR uyumlu, TÃ¼rkiye ve global ÅŸirket verilerini toplayan, normalize eden ve aranabilir hale getiren kurumsal pazarlama verisi platformu.

## ğŸ¯ Ã–zellikler

- **Otomatik Veri Toplama**: Google Search, Google Places, web siteleri ve sosyal medya platformlarÄ±ndan halka aÃ§Ä±k ÅŸirket verilerini toplar
- **AkÄ±llÄ± Deduplikasyon**: GeliÅŸmiÅŸ entity resolution algoritmalarÄ± ile tekrar eden kayÄ±tlarÄ± otomatik birleÅŸtirir
- **KVKK/GDPR Uyumlu**: KiÅŸisel veri minimizasyonu, silme hakkÄ± (RTBF) ve uyum raporlamasÄ±
- **GÃ¼Ã§lÃ¼ Arama**: OpenSearch/Elasticsearch tabanlÄ± hÄ±zlÄ± ve esnek arama
- **Veri Kalitesi**: Great Expectations ile otomatik veri kalite kontrolleri
- **Segmentasyon**: Åirketleri otomatik olarak pazarlama segmentlerine ayÄ±rÄ±r
- **RESTful API**: FastAPI ile modern, hÄ±zlÄ± ve dokÃ¼mante edilmiÅŸ API
- **Orkestrasyon**: Apache Airflow ile zamanlanmÄ±ÅŸ ve yÃ¶netilebilir ETL pipeline'larÄ±

## ğŸ“‹ Gereksinimler

- Docker & Docker Compose
- Python 3.11+
- 8GB+ RAM
- 20GB+ Disk alanÄ±

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Projeyi KlonlayÄ±n
```bash
git clone https://github.com/your-org/marketing-data-platform.git
cd marketing-data-platform
```

### 2. Ortam DeÄŸiÅŸkenlerini AyarlayÄ±n
```bash
cp .env.example .env
# .env dosyasÄ±nÄ± dÃ¼zenleyerek API anahtarlarÄ±nÄ±zÄ± ekleyin:
# - GOOGLE_PLACES_API_KEY
# - GOOGLE_CSE_API_KEY (Custom Search Engine)
# - GOOGLE_CSE_CX (Custom Search Engine ID)
```

### 3. Servisleri BaÅŸlatÄ±n
```bash
make up
```

Bu komut tÃ¼m servisleri baÅŸlatacaktÄ±r:
- PostgreSQL (5432)
- OpenSearch (9200)
- Redis (6379)
- MinIO (9000/9001)
- FastAPI (8000)
- Airflow (8080)
- Grafana (3000)

### 4. VeritabanÄ±nÄ± BaÅŸlatÄ±n
```bash
make db-init
make index-create
```

### 5. Ä°lk Veri ToplamayÄ± BaÅŸlatÄ±n
```bash
make crawl
```

## ğŸ“š KullanÄ±m

### API Endpoints

**Arama:**
```bash
curl -X POST "http://localhost:8000/api/v1/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "teknoloji ÅŸirketi istanbul",
    "filters": {"city": "Ä°stanbul", "priority_tier": "A"},
    "page": 1,
    "page_size": 20
  }'
```

**Åirket DetayÄ±:**
```bash
curl "http://localhost:8000/api/v1/company/{company_id}"
```

**Veri Ä°hracatÄ±:**
```bash
curl -X POST "http://localhost:8000/api/v1/export" \
  -H "Content-Type: application/json" \
  -d '{
    "format": "csv",
    "filters": {"city": "Ä°stanbul"},
    "limit": 1000
  }' > export.csv
```

**Analitik:**
```bash
curl "http://localhost:8000/api/v1/analytics"
```

### Airflow DAG YÃ¶netimi

Airflow web arayÃ¼zÃ¼ne http://localhost:8080 adresinden eriÅŸebilirsiniz:
- KullanÄ±cÄ±: admin
- Åifre: admin

Mevcut DAG'lar:
- `company_data_etl`: Ana ETL pipeline (gÃ¼nlÃ¼k)
- Discover â†’ Fetch â†’ Parse â†’ Normalize â†’ Validate â†’ Deduplicate â†’ Enrich â†’ Load

### Veri Kalitesi Kontrolleri

```bash
make quality-check
```

Bu komut Great Expectations kurallarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r ve veri kalite raporu oluÅŸturur.

### Arama Ä°ndeksi YÃ¶netimi

```bash
# Ä°ndeksi yeniden oluÅŸtur
make index-reindex

# Ä°ndeks istatistikleri
curl "http://localhost:9200/companies/_stats"
```

## ğŸ—ï¸ Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Veri KaynaklarÄ±                      â”‚
â”‚  Google Search â”‚ Google Places â”‚ Websites â”‚ Social Media    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Collectors (Python)                     â”‚
â”‚  Rate Limiting â”‚ Robots.txt â”‚ Caching â”‚ PII Filtering       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Apache Airflow (DAG)                      â”‚
â”‚  Discover â†’ Fetch â†’ Parse â†’ Normalize â†’ Validate â†’ Dedupe   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼               â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚ â”‚OpenSearchâ”‚ â”‚  MinIO  â”‚ â”‚ Redis  â”‚
â”‚   (OLTP)     â”‚ â”‚ (Search) â”‚ â”‚(Storage)â”‚ â”‚(Cache) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI (REST API)                      â”‚
â”‚  Search â”‚ Filter â”‚ Export â”‚ Analytics â”‚ Compliance          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Veri ÅemasÄ±

### Unified Company Schema v1

```json
{
  "identity": {
    "legal_name": "string",
    "trade_name": "string",
    "company_type": "enum",
    "country": "ISO code",
    "city": "string",
    "district": "string"
  },
  "web_presence": {
    "website_url": "URL",
    "social_links": {},
    "google_places": {}
  },
  "contacts": {
    "emails_public": ["email"],
    "phones_public": ["phone"],
    "address_public": "string"
  },
  "business_meta": {
    "industry": "string",
    "size": "enum",
    "founding_year": "integer",
    "keywords": ["string"]
  }
}
```

## ğŸ”’ KVKK/GDPR Uyumluluk

Platform, veri koruma yÃ¶netmeliklerine tam uyum saÄŸlar:

### Veri Minimizasyonu
- YalnÄ±zca halka aÃ§Ä±k kurumsal veriler toplanÄ±r
- KiÅŸisel e-postalar ve telefonlar otomatik filtrelenir
- KiÅŸi odaklÄ± profiller oluÅŸturulmaz

### Silme HakkÄ± (RTBF)
```bash
curl -X POST "http://localhost:8000/api/v1/compliance" \
  -H "Content-Type: application/json" \
  -d '{
    "action": "delete",
    "identifier": "company-id",
    "requester_email": "legal@company.com"
  }'
```

### Veri Ä°hracat HakkÄ±
```bash
curl -X POST "http://localhost:8000/api/v1/compliance" \
  -H "Content-Type: application/json" \
  -d '{
    "action": "export",
    "identifier": "company-id",
    "requester_email": "legal@company.com"
  }'
```

### Uyum Raporu
```bash
make test-compliance
```

## ğŸ§ª Test

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
make test

# Sadece deduplikasyon testleri
make test-unit

# KVKK/GDPR uyum testleri
make test-compliance

# Kod kalitesi kontrolleri
make lint
```

## ğŸ“ˆ Ä°zleme ve Metrikler

### Prometheus Metrikleri
http://localhost:9090

### Grafana Dashboard
http://localhost:3000 (admin/admin)

### SaÄŸlÄ±k KontrolÃ¼
```bash
curl http://localhost:8000/api/v1/health
```

## ğŸ› ï¸ GeliÅŸtirme

### GeliÅŸtirme OrtamÄ±nÄ± BaÅŸlat
```bash
make dev
```

Bu komut ek olarak baÅŸlatÄ±r:
- Jupyter Notebook (8888)
- pgAdmin (5050)
- MailHog (8025)

### Yeni Collector Ekleme

1. `src/collectors/` altÄ±nda yeni collector oluÅŸturun
2. `BaseCollector` sÄ±nÄ±fÄ±ndan tÃ¼retin
3. `collect()` ve `parse()` metodlarÄ±nÄ± implement edin
4. Airflow DAG'a ekleyin

### Veri Kalite KuralÄ± Ekleme

1. `src/quality/expectations.py` dosyasÄ±nÄ± dÃ¼zenleyin
2. Yeni expectation ekleyin
3. `make quality-check` ile test edin

## ğŸš¢ Production Deployment

### Kubernetes Deployment
```bash
kubectl apply -f k8s/
```

### Docker Swarm
```bash
docker stack deploy -c docker-compose.prod.yml marketing-platform
```

### Yedekleme
```bash
# VeritabanÄ± yedekleme
make db-backup

# Geri yÃ¼kleme
make db-restore
```

## ğŸ“ Makefile KomutlarÄ±

```bash
make help         # TÃ¼m komutlarÄ± listele
make up           # Servisleri baÅŸlat
make down         # Servisleri durdur
make logs         # LoglarÄ± gÃ¶ster
make crawl        # Veri toplamayÄ± baÅŸlat
make transform    # dbt dÃ¶nÃ¼ÅŸÃ¼mlerini Ã§alÄ±ÅŸtÄ±r
make test         # Testleri Ã§alÄ±ÅŸtÄ±r
make clean        # Temizlik yap
```

## ğŸ¤ KatkÄ±da Bulunma

1. Fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add amazing feature'`)
4. Branch'e push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“œ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ†˜ Destek

- ğŸ“§ Email: support@marketingplatform.com
- ğŸ“š DokÃ¼mantasyon: [docs/](docs/)
- ğŸ› Bug Report: [GitHub Issues](https://github.com/your-org/marketing-data-platform/issues)

## ğŸ™ TeÅŸekkÃ¼rler

Bu platform aÅŸaÄŸÄ±daki aÃ§Ä±k kaynak projeleri kullanmaktadÄ±r:
- Apache Airflow
- OpenSearch
- FastAPI
- dbt
- Great Expectations
- PostgreSQL
- Redis

---
**Not**: Bu platform yalnÄ±zca halka aÃ§Ä±k verileri toplar ve KVKK/GDPR yÃ¶netmeliklerine tam uyum saÄŸlar. Platform kullanÄ±cÄ±larÄ±, yerel veri koruma yasalarÄ±na uymaktan sorumludur.